## SNS for Fan out.

Suppose we want to send an email message when an image upload event occurs, as well as process the image. Rather than include the emailing functionality in the same lambda that processes the image, handling it in a separate function is a better design - separation of concerns principle. The updated design for our app looks as follows:

![][arch]

[We will address the emailing part of the above architecture in the next section.]

Now, S3 publishes a message on an SNS topic/channel whenever an image file is uploaded to the bucket. The topic has two SQS subscribers, feeding batches of upload event messages to their respective lambda functions.

In `lib/eda-app-stack.ts`, make the following changes:

+ Rename the current queue to imageProcessQueue:
~~~ts
    const imageProcessQueue = new sqs.Queue(this, "img-created-queue", {
      receiveMessageWaitTime: cdk.Duration.seconds(10),
    });
~~~
+ Add an SNS topic (after the queue declaration):
~~~ts
    const newImageTopic = new sns.Topic(this, "NewImageTopic", {
      displayName: "New Image topic",
    }); 
~~~
+ Change the S3 event notification destination type to SNS:  
~~~ts
    imagesBucket.addEventNotification(
        s3.EventType.OBJECT_CREATED,
        new s3n.SnsDestination(newImageTopic)  // Changed
    );
~~~
+ Add a subscriber to the SNS topic:
~~~ts
    newImageTopic.addSubscription(
      new subs.SqsSubscription(imageProcessQueue)
    );
~~~

Messages written to an SNS topic or SQS queue are stored in stringified form. Therefore, a lambda function must parse them before processing. Our lambda function must perform two parsing operations because the S3 event message passes through two AWS integration resources - a topic and a queue. In `lambdas/processImage.ts`, replace the code with the following:
~~~ts
/* eslint-disable import/extensions, import/no-absolute-path */
import { SQSHandler } from "aws-lambda";
import {
  GetObjectCommand,
  PutObjectCommandInput,
  GetObjectCommandInput,
  S3Client,
  PutObjectCommand,
} from "@aws-sdk/client-s3";

const s3 = new S3Client();

export const handler: SQSHandler = async (event) => {
  console.log("Event ", event);
  for (const record of event.Records) {
    const recordBody = JSON.parse(record.body);  // Parse SQS message
    const snsMessage = JSON.parse(recordBody.Message); // Parse SNS message

    if (snsMessage.Records) {
      console.log("Record body ", JSON.stringify(snsMessage));
      for (const messageRecord of snsMessage.Records) {
        const s3e = messageRecord.s3;
        const srcBucket = s3e.bucket.name;
        // Object key may have spaces or unicode non-ASCII characters.
        const srcKey = decodeURIComponent(s3e.object.key.replace(/\+/g, " "));
        let origimage = null;
        try {
          // Download the image from the S3 source bucket.
          const params: GetObjectCommandInput = {
            Bucket: srcBucket,
            Key: srcKey,
          };
          origimage = await s3.send(new GetObjectCommand(params));
          // Process the image ......
        } catch (error) {
          console.log(error);
        }
      }
    }
  }
};
~~~
We will add the emailing functionality shortly. Redeploy the stack (cdk deploy). Test it by uploading an image - we will use the same image but give it a different S3 key:
~~~bash
Â£ aws s3 cp ./images/sunflower.jpeg  s3://your_bucket_name/image2.jpeg
~~~
In Cloudwatch, find the stream generated by the lambda handler for the above upload:

![][sns]

![][s3]

Commit this work:
~~~bash
$ git add -A
$ git commit -m "Started Fan out for S3 image upload."
~~~

[arch]: ./img/arch.png
[s3]: ./img/s3.png
[sns]: ./img/sns.png


