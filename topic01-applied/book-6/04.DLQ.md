## SQS Dead Letter Queue.

You have now completed the assessed part of this lab. Ensure you have uploaded the URL of the Github repo you used to Moodle.

The remaining sections of this lab are additional preparation for the final assignment.

----------------------------

In this section we will demonstrate the DLQ aspect of SQS queues using the demo app discussed in the lectures. The app's architecture is illustrated below:

![][dlqdemo]

Download [this archive][sqsstart], unzip it, import it into VS Code, and run the following commands:

~~~bash
$ npm install
$ npm run schema
$ cdk deploy
~~~
Note the deploy command outputs the name of the generate orders lambda function - we will need this later.

Some important configuration settings to note about the app's infrastructure are  as follows:

+ The max concurrency limit for the process orders lambda function is set to two.
+ The max concurrency limit for the process failed/bad orders lambda function is also two.
+ The maxReceiveCount of the dead letter queue is set to one. This means a faulty order batch is sent to the DLQ after the first attempt at processing them - no retries are allowed.


In `lambdas/generateOrders.ts`, there is an array of ten orders, of which one is invalid as it is missing a customer address property (see User X order). The function sends the entire array to the queue for processing. Trigger the execution of this handler from the command line using the AWS CLI (use your function name in the command):

~~~bash
$ aws lambda invoke --function-name SQSDemo-Stk-Generate
OrdersFnC9717F1B-AJMPoUxnfZho response.json
~~~

In CloudWatch, this app should have three log groups (there will be a short delay before all groups are visible). 

![][sqsgroups]

Select the `ProcessOrdersFn` group. It has two log streams, one for each concurrent instance of the handler. One of the streams has the bad order. The screenshots below show the streams for a sample execution:

![][sqsstream1]

![][sqsstream2]

In the above case, the two handlers received the following batches:

+ Handler 1 - Orders from User1, user2 and user 8
+ Handler 2 - Orders from User3, user4, user 5, user 6, user7, user9, and userX

Because the DLQ's maxReceiveCount is set to one, all the orders in the bad batch (Handler 2 above) are sent to the DLQ. Go to the streams for the FailedOrdeersFn log group and confirm this.

In `lib/sqs-demo-app-stack.ts`, set the maxReceiveCount of the DLQ to two:
~~~ts
    const ordersQueue = new sqs.Queue(this, "orders-queue", {
      deadLetterQueue: {
        queue: badOrdersQueue,
        // # of rejections by consumer (lambda function)
        maxReceiveCount: 2,    // Changed
      },
    });
~~~
Redeploy the stack. In the Cloudwatch web console, delete all the log groups to clean up.
Trigger the generate orders handler:
 ~~~bash
$ aws lambda invoke --function-name SQSDemo-Stk-Generate
OrdersFnC9717F1B-AJMPoUxnfZho response.json
~~~
By examining the log streams of the processOrdersFn log group, you will notice that the batch containing the bad order is processed a second time. In the second attempt, the batche's entries will be split into two smaller batches for processing by the two concurrent handler instances. The net effect is the DLQ receives a smaller batch on this occasion. 

An alternative way of reducing the appearance of good orders in the DLQ is to increase the 
maxConcurrency of process orders function:
~~~ts
    processOrdersFn.addEventSource(
      new SqsEventSource(ordersQueue, {
        maxBatchingWindow: Duration.seconds(10),
        maxConcurrency: 2,  // Increase this value
      })
    );
~~~
Experiment with this yourself.

## Clean Up.

Delete this stack infrastructure:
~~~bash
$ cdk destroy
~~~


[sqsstart]: ./img/sqsstart.zip
[dlqdemo]: ./img/dlqdemo.png
[sqsgroups]: ./img/sqsgroups.png
[sqsstream1]: ./img/sqsstream1.png
[sqsstream2]: ./img/sqsstream2.png
