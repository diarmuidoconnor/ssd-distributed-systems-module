## SQS Dead Letter Queue.

This section will demonstrate the DLQ aspect of SQS queues using the demo app discussed in the lectures. The app's architecture is illustrated below:

![][dlqdemo]

Download [this archive][sqsstart], unzip it, import it into VS Code, and run the following commands:

~~~bash
$ npm install
$ npm run schema
$ cdk deploy
~~~
Note that the deploy command outputs the name of the generate-orders lambda function - we will need this later.

There are some configuration settings for the app's infrastructure to note:

+ The max concurrency limit for the process-orders and failedOrders lambda functions are set to two.
+ The dead letter queue's maxReceiveCount is set to one. It means a bad order batch (a batch with at least one invalid order) is sent to the DLQ after the first attempt at processing it â€” no retries are allowed.

In `lambdas/generateOrders.ts`, an array is generated containing ten orders, one of which is invalid as it is missing an address property (the User X order). The function writes the entire array to the orders queue. Trigger the execution of this handler from the command line using the AWS CLI (use your function name in the command):
~~~bash
e.g. 
$ aws lambda invoke --function-name SQSDemo-Stk-Generate
OrdersFnC9717F1B-AJMPoUxnfZho response.json
~~~

This causes the creation of three log groups in CloudWatch. There will be a short delay before all groups are listed due to the polling frequency of the orders queue by its consumer lambda function. 

![][sqsgroups]

Click the `ProcessOrdersFn` log group. It has two log streams, one for each concurrent instance of the function. Find the stream that has the bad order (User X) - the screenshots below show the  two streams for a sample execution:

![][sqsstream1]

![][sqsstream2]

In the above case, the two handlers received the following batches:

+ Handler 1 - Orders from user1, user 2 and user 8
+ Handler 2 - Orders from user 3, user 4, user 5, user 6, user7, user9, and user X

Because the DLQ's maxReceiveCount is set to one, all the orders in the bad batch (Handler 2 above) are sent to the DLQ immediately. The FailedOrdeersFn handler is a consumer of the DLQ. Go to its log streams and confirm that it received all the 'bad batch' orders, which include some valid orders.

In `lib/sqs-demo-app-stack.ts`, set the maxReceiveCount of the DLQ to two:
~~~ts
    const ordersQueue = new sqs.Queue(this, "orders-queue", {
      deadLetterQueue: {
        queue: badOrdersQueue,of 
        // # of rejections by consumer (lambda function)
        maxReceiveCount: 2,    // Changed
      },
    });
~~~
Redeploy the stack. 

In the Cloudwatch web console, delete all the log groups to clean up, and then trigger the generate orders handler:
 ~~~bash
e.g.
$ aws lambda invoke --function-name SQSDemo-Stk-Generate
OrdersFnC9717F1B-AJMPoUxnfZho response.json
~~~
By examining the log streams of the processOrdersFn, you will notice that the batch containing the bad order has been processed twice. In the second attempt, the batch's entries are split into two smaller batches, one for each of the two concurrent handler instances. The net effect is that the DLQ receives a smaller 'bad batch'. 

An alternative way of reducing the appearance of good orders in the DLQ is to increase the maxConcurrency of the process-orders function:
~~~ts
    processOrdersFn.addEventSource(
      new SqsEventSource(ordersQueue, {
        maxBatchingWindow: Duration.seconds(10),
        maxConcurrency: 2,  // Increase this value to 3
      })
    );
~~~
Experiment with this yourself.

## Clean Up.

Delete this stack infrastructure:
~~~bash
$ cdk destroy
~~~


[sqsstart]: ./img/sqsstart.zip
[dlqdemo]: ./img/dlqdemo.png
[sqsgroups]: ./img/sqsgroups.png
[sqsstream1]: ./img/sqsstream1.png
[sqsstream2]: ./img/sqsstream2.png
